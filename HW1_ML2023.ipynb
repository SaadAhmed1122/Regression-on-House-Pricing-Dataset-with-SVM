{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaadAhmed1122/Regression-on-House-Pricing-Dataset-with-SVM/blob/main/HW1_ML2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm8WC30y1mRD"
      },
      "source": [
        "#  Regression on House Pricing Dataset with SVM\n",
        "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
        "\n",
        "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
        "\n",
        "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK4Itd_b1mRO"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In the notebook you will first:\n",
        "- split the data into training, validation, and test\n",
        "- standardize the data\n",
        "\n",
        "You will then be asked to learn various SVM models, in particular:\n",
        "- for each of the kernels ‘linear’, ‘poly’, ‘rbf’, and ‘sigmoid’, you will learn the best model having to choose among various values of some hyperparameters; the choice of hyperparameters must be done with 5-fold cross-validation\n",
        "- choose the best kernel, using a validation approach (not cross-validation)\n",
        "- learn the best SVM model overall\n",
        "\n",
        "You will then be asked to estimate the generalization error of the best SVM model you report.\n",
        "\n",
        "At the end, just for comparison, you will alsk be asked to learn a standard linear regression model (with squared loss), and estimate its generalization error.\n",
        "\n",
        "### IMPORTANT\n",
        "- Note that in each of the above steps you will have to choose the appropriate split of the data (see the first bullet point above)\n",
        "- The code should run without requiring modifications even if some best choice of parameters, changes; for example, you should not pass the best value of hyperparameters \"manually\" (i.e., passing the values as input parameters to the models). The only exception is in the TO DO titled 'ANSWER THE FOLLOWING'\n",
        "- For SVM, since the values to be predicted are all in the thousands of dollars, you will need to always set epsilon=1000\n",
        "- Do not change the printing instructions (other than adding the correct variable name for your code), and do not add printing instructions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyJpXKMG1mRR"
      },
      "source": [
        "## TO DO - INSERT YOUR NUMERO DI MATRICOLA BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "QnNkgviU1mRT"
      },
      "outputs": [],
      "source": [
        "#put here your ``numero di matricola''\n",
        "numero_di_matricola = 2044003"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg9eXFmX1mRW"
      },
      "source": [
        "The following code loads all required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "id": "eaArDwjS1mRX"
      },
      "outputs": [],
      "source": [
        "#import all packages needed\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "from sklearn import model_selection\n",
        "from sklearn import linear_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "EAM7JXk61mRY"
      },
      "source": [
        "The code below loads the data and remove samples with missing values. It also prints the number of samples in the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2sd6wHL1mRY",
        "outputId": "15cc69b2-d2c1-4f00-8f02-19b70409ba09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 3164\n"
          ]
        }
      ],
      "source": [
        "#load the data - do not change the path below!\n",
        "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
        "\n",
        "#remove the data samples with missing values (NaN)\n",
        "df = df.dropna()\n",
        "\n",
        "Data = df.values\n",
        "m = Data.shape[0]\n",
        "Y = Data[:m,2]\n",
        "X = Data[:m,3:]\n",
        "\n",
        "print(\"Total number of samples:\",m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "2IrgkmXY1mRZ"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnfVQLkv1mRa"
      },
      "source": [
        "## TO DO - SPLIT DATA INTO TRAINING, VALIDATION, AND TESTING, WITH THE FOLLOWING PERCENTAGES: 60%, 20%, 20%\n",
        "\n",
        "Use the train_test_split function from sklearn.model_selection to do it; in every call fix random_state to your numero_di_matricola. At the end, you should store the data in the following variables:\n",
        "- Xtrain, Ytrain: training data\n",
        "- Xval, Yval: validation data\n",
        "- Xtrain_val, Ytrain_val: training and validation data\n",
        "- Xtest, Ytest: test data\n",
        "\n",
        "The code then prints the number of samples in Xtrain, Xval, Xtrain_val, and Xtest\n",
        "\n",
        "IMPORTANT:\n",
        "- first split the data into training+validation and test; the first part of the data in output from train_test_split must correspond to the training+validation\n",
        "- then split training+validation into training and validation; the first part of the data in output from train_test_split must correspond to the training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZI9-cXK1mRb",
        "outputId": "aef9f8e1-59ba-4f3b-a2c0-d6fcf41abb38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size:  2024\n",
            "Validation size:  507\n",
            "Training and validation size 2531\n",
            "Test size 633\n"
          ]
        }
      ],
      "source": [
        "#split the data into training+validation and test\n",
        "X_train_val, Xtest, Y_train_val, Ytest = train_test_split(X, Y, test_size=0.2, random_state=202324)\n",
        "\n",
        "#split training+validation into training and validation\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=202324)\n",
        "\n",
        "print(\"Training size: \", Xtrain.shape[0])\n",
        "print(\"Validation size: \", Xval.shape[0])\n",
        "print(\"Training and validation size\",X_train_val.shape[0])\n",
        "print(\"Test size\",Xtest.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqjkzEF61mRc"
      },
      "source": [
        "## TO DO - STANDARDIZE THE DATA\n",
        "\n",
        "Standardize the data using the preprocessing.StandardScaler from scikit learn.\n",
        "\n",
        "If V is the name of the variable storing part of the data, the corresponding standardized version should be stored in V_scaled. For example, the scaled version of Xtrain should be stored in Xtrain_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "BfzO0h2g1mRd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
        "Xval_scaled = scaler.transform(Xval)\n",
        "Xtrain_val_scaled = scaler.transform(X_train_val)\n",
        "Xtest_scaled = scaler.transform(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "OI0gX1ky1mRd"
      },
      "source": [
        "# SVM models: learning the best model for each kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KicXKTbi1mRe"
      },
      "source": [
        "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR LINEAR KERNEL\n",
        "\n",
        "Consider svm.SVR and linear kernel. Consider the following hyperparameters and their values:\n",
        "- C: 0.1, 1, 10, 100, 1000\n",
        "\n",
        "Leave all other input parameters to default.\n",
        "\n",
        "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
        "\n",
        "Print the best value of the hyperparameters (they are in the attribute best_params_ from GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P5bhdI691mRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2872608f-d7a3-46fd-93ff-e9677bc19348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear SVM\n",
            "Best value for hyperparameters:  1000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "#set up the parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "#initialize the SVR model\n",
        "model = SVR(kernel='linear')\n",
        "\n",
        "#perform the grid search with 5-fold cross-validation\n",
        "grid = GridSearchCV(model, param_grid, cv=5)\n",
        "grid.fit(Xtrain_scaled, Ytrain)\n",
        "\n",
        "print(\"\\nLinear SVM\")\n",
        "# COMPLETE\n",
        "print(\"Best value for hyperparameters: \", grid.best_params_['C'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXOMkPeu1mRe"
      },
      "source": [
        "## TO DO - LEARN A MODEL WITH LINEAR KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
        "\n",
        "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
        "\n",
        "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
        "\n",
        "Print the training score of the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7jn0Pktl1mRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9efd06-0b95-451b-c58b-6589f53b88c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score:  0.6444660629886867\n"
          ]
        }
      ],
      "source": [
        "svr_linear_best = SVR(kernel='linear', C=grid.best_params_['C'])\n",
        "svr_linear_best.fit(Xtrain_scaled, Ytrain)\n",
        "print(\"Training score: \", svr_linear_best.score(Xtrain_scaled, Ytrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0m7lQpd1mRf"
      },
      "source": [
        "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR POLY KERNEL\n",
        "\n",
        "Consider svm.SVR and polynomial kernel. Consider the following hyperparameters and their values:\n",
        "- C: 0.1, 1, 10, 100, 1000\n",
        "- degree: 2, 3, 4\n",
        "\n",
        "Leave all other input parameters to default.\n",
        "\n",
        "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
        "\n",
        "Print the best value of the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "id": "9GQ-9O_n1mRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda1afc7-48ab-45f5-d67c-501290a00ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Poly SVM\n",
            "Best value for hyperparameters:  {'C': 1000, 'degree': 3}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nPoly SVM\")\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'degree': [2, 3, 4]}\n",
        "svr_poly = SVR(kernel='poly')\n",
        "grid_search = GridSearchCV(svr_poly, param_grid, cv=5)\n",
        "grid_search.fit(Xtrain_scaled, Ytrain)\n",
        "print(\"Best value for hyperparameters: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "8PtpPvVb1mRg"
      },
      "source": [
        "## TO DO - LEARN A MODEL WITH POLY KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
        "\n",
        "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
        "\n",
        "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
        "\n",
        "Print the training score of the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "id": "2ou0V4LG1mRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c3ce4e-c73f-4cbf-fbfa-5855fc11b6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score:  0.5638064537222263\n"
          ]
        }
      ],
      "source": [
        "svr_poly_best = SVR(kernel='poly', C=grid_search.best_params_['C'], degree=grid_search.best_params_['degree'])\n",
        "svr_poly_best.fit(Xtrain_scaled, Ytrain)\n",
        "print(\"Training score: \", svr_poly_best.score(Xtrain_scaled, Ytrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYPPhLfl1mRh"
      },
      "source": [
        "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR RBF KERNEL\n",
        "\n",
        "Consider svm.SVR and RBF kernel. Consider the following hyperparameters and their values:\n",
        "- C: 0.1, 1, 10, 100, 1000\n",
        "- gamma: 0.01\n",
        "\n",
        "Leave all other input parameters to default.\n",
        "\n",
        "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
        "\n",
        "Print the best value of the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "id": "4Ns07PNO1mRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b68c3f-cebd-430d-f0e9-5d18e73ceabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RBF SVM\n",
            "Best value for hyperparameters:  {'C': 1000, 'gamma': 0.01}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRBF SVM\")\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01]}\n",
        "svr_rbf = SVR(kernel='rbf')\n",
        "grid_search = GridSearchCV(svr_rbf, param_grid, cv=5)\n",
        "grid_search.fit(Xtrain_scaled, Ytrain)\n",
        "print(\"Best value for hyperparameters: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KSWNFDq1mRh"
      },
      "source": [
        "## TO DO - LEARN A MODEL WITH RBF KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
        "\n",
        "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
        "\n",
        "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
        "\n",
        "Print the training score of the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "id": "vkEVeZCx1mRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59bd3b7-6e70-4d5d-c8ec-add17bf1a816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score:  0.13067559014716523\n"
          ]
        }
      ],
      "source": [
        "svr_rbf_best = SVR(kernel='rbf', C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
        "svr_rbf_best.fit(Xtrain_scaled, Ytrain)\n",
        "print(\"Training score: \", svr_rbf_best.score(Xtrain_scaled, Ytrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "AJusXs-C1mRi"
      },
      "source": [
        "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR SIGMOID KERNEL\n",
        "\n",
        "Consider svm.SVR and sigmoid kernel. Consider the following hyperparameters and their values:\n",
        "- C: 0.1, 1, 10, 100, 1000\n",
        "- gamma: 0.01\n",
        "- coef0: 0, 1\n",
        "\n",
        "Leave all other input parameters to default.\n",
        "\n",
        "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
        "\n",
        "Print the best value of the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "id": "1epyU_Ew1mRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d6f5d6-a363-4493-f9fd-8f61459ef594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sigmoid SVM\n",
            "Best value for hyperparameters:  {'C': 1000, 'coef0': 0, 'gamma': 0.01}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSigmoid SVM\")\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01], 'coef0': [0, 1]}\n",
        "svr_sigmoid = SVR(kernel='sigmoid')\n",
        "grid_search = GridSearchCV(svr_sigmoid, param_grid, cv=5)\n",
        "grid_search.fit(Xtrain_scaled, Ytrain)\n",
        "\n",
        "print(\"Best value for hyperparameters: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "dpHoX0iX1mRj"
      },
      "source": [
        "## TO DO - LEARN A MODEL WITH SIGMOID KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
        "\n",
        "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
        "\n",
        "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
        "\n",
        "Print the training score of the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "BWVAsJSo1mRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a80d0f-881e-47df-dcdc-048ba618902a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score:  0.1212882366856074\n"
          ]
        }
      ],
      "source": [
        "svr_sigmoid_best = SVR(kernel='sigmoid', C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'], coef0=grid_search.best_params_['coef0'])\n",
        "svr_sigmoid_best.fit(Xtrain_scaled, Ytrain)\n",
        "print(\"Training score: \", svr_sigmoid_best.score(Xtrain_scaled, Ytrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "OV-90UWb1mRj"
      },
      "source": [
        "## TO DO - USE VALIDATION TO CHOOSE THE BEST MODEL AMONG THE ONES LEARNED FOR THE VARIOUS KERNELS\n",
        "\n",
        "Use validation to choose the best model among the four ones (one for each kernel) you have learned above.\n",
        "\n",
        "Print, following exactly the order described here, with 1 value for each line:\n",
        "- the validation score of SVM with linear kernel (the template below does not include such print)\n",
        "- the validation score of SVM with polynomial kernel (the template below does not include such print)\n",
        "- the validation score of SVM with rbf kernel (the template below does not include such print)\n",
        "- the validation score of SVM with sigmoid kernel (the template below does not include such print)\n",
        "- the best kernel (e.g., sigmoid)\n",
        "- the validation score of the best kernel\n",
        "\n",
        "For the first 4 prints, use the format: \"kernel validation score: \". For example, for linear kernel \"Linear validation score: \", for rbf \"rbf validation score: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "id": "PgkGYN7J1mRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697eedb7-3bae-4bb1-8f1b-f54a76631ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "VALIDATION TO CHOOSE SVM KERNEL\n",
            "Linear validation score: 0.6238723324029545\n",
            "Polynomial validation score: 0.6846256737672345\n",
            "RBF validation score: 0.09738280602899996\n",
            "Sigmoid validation score: 0.10640475149197981\n",
            "Best kernel:  polynomial\n",
            "Validation score of best kernel:  0.6846256737672345\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nVALIDATION TO CHOOSE SVM KERNEL\")\n",
        "\n",
        "# COMPLETE - INCLUDING THE FIRST 4 PRINT FROM THE LIST ABOVE\n",
        "# compute the validation score of SVM with linear kernel\n",
        "svr_linear_val_score = svr_linear_best.score(Xval_scaled, Yval)\n",
        "print(\"Linear validation score:\", svr_linear_val_score)\n",
        "\n",
        "\n",
        "#compute the validation score of SVM with polynomial kernel\n",
        "svr_poly_val_score = svr_poly_best.score(Xval_scaled, Yval)\n",
        "print(\"Polynomial validation score:\", svr_poly_val_score)\n",
        "\n",
        "#compute the validation score of SVM with rbf kernel\n",
        "svr_rbf_val_score = svr_rbf_best.score(Xval_scaled, Yval)\n",
        "print(\"RBF validation score:\", svr_rbf_val_score)\n",
        "\n",
        "#compute the validation score of SVM with sigmoid kernel\n",
        "svr_sigmoid_val_score = svr_sigmoid_best.score(Xval_scaled, Yval)\n",
        "print(\"Sigmoid validation score:\", svr_sigmoid_val_score)\n",
        "\n",
        "#find the best kernel and its validation score\n",
        "kernel_scores = {'linear': svr_linear_val_score, 'polynomial': svr_poly_val_score, 'rbf': svr_rbf_val_score,\n",
        "                 'sigmoid': svr_sigmoid_val_score}\n",
        "best_kernel = max(kernel_scores, key=kernel_scores.get)\n",
        "best_kernel_score = kernel_scores[best_kernel]\n",
        "\n",
        "print(\"Best kernel: \", best_kernel)\n",
        "print(\"Validation score of best kernel: \", best_kernel_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yedktVQA1mRk"
      },
      "source": [
        "## TO DO - LEARN THE FINAL MODEL FOR WHICH YOU WANT TO ESTIMATE THE GENERALIZATION ERROR\n",
        "\n",
        "Learn the final model (i.e., the one you would use to make predictions about future data).\n",
        "\n",
        "Print the score of the model on the data used to learn it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "id": "V9elijNC1mRl",
        "outputId": "d7535ab6-490b-413c-c76d-2987c44f8130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAINING SCORE BEST MODEL\n",
            "Score of the best model on the data used to learn it:  119695826356.8328\n",
            "Score of the best model on the data used to learn it:  0.13067559014716523\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"\\nTRAINING SCORE BEST MODEL\")\n",
        "#initialize the SVR model with the best hyperparameters\n",
        "model = SVR(kernel='rbf', C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
        "\n",
        "#train the model on the entire training set\n",
        "model.fit(Xtrain_scaled, Ytrain)\n",
        "\n",
        "#evaluate the model on the training set\n",
        "Y_pred = model.predict(Xtrain_scaled)\n",
        "score = mean_squared_error(Ytrain, Y_pred)\n",
        "print(\"Score of the best model on the data used to learn it: \", score)\n",
        "print(\"Score of the best model on the data used to learn it: \", model.score(Xtrain_scaled, Ytrain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "H_h3Q1ny1mRl"
      },
      "source": [
        "## TO DO - PRINT THE ESTIMATE  OF THE GENERALIZATION ERROR FOR THE FINAL MODEL\n",
        "\n",
        "Print the estimate of the generalization \"score\" for the final model. The generalization \"score\" is the score computed on the data used to estimate the generalization error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "id": "ttNU8SuS1mRl",
        "outputId": "93c1ce4f-b07f-4204-fe57-d0f0b3922517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GENERALIZATION SCORE BEST MODEL\n",
            "Estimate of the generalization score for best SVM model:  -0.039856511099357506\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVR\n",
        "print(\"\\nGENERALIZATION SCORE BEST MODEL\")\n",
        "model = SVR(kernel='rbf', C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
        "\n",
        "#train the model on the entire training set\n",
        "model.fit(Xtrain_scaled, Ytrain)\n",
        "\n",
        "# Estimate the generalization error using K-fold cross validation\n",
        "num_folds = 10\n",
        "cv = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "cv_scores = []\n",
        "for train_index, test_index in cv.split(Xtrain_scaled, Ytrain):\n",
        "    X_train, X_test = Xtrain_scaled[train_index], Xtrain_scaled[test_index]\n",
        "    y_train, y_test = Ytrain[train_index], Ytrain[test_index]\n",
        "\n",
        "    svr = SVR(kernel='rbf', C=100, gamma=0.1)\n",
        "    svr.fit(X_train, y_train)\n",
        "    score = svr.score(X_test, y_test)\n",
        "    cv_scores.append(score)\n",
        "\n",
        "generalization_error = np.mean(cv_scores)\n",
        "\n",
        "print(\"Estimate of the generalization score for best SVM model: \", generalization_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "PSp9bW331mRm"
      },
      "source": [
        "## TO DO - ANSWER THE FOLLOWING\n",
        "\n",
        "Print the training score (score on data used to train the model) and the generalization score (score on data used to estimate the generalization error) of the final SVM model THAT YOU OBTAIN WHEN YOU RUN THE CODE, one per line, printing the smallest one first. NOTE: THE VALUES HERE SHOULD BE HARDCODED\n",
        "\n",
        "Print you answer (yes/no) to the following question: does the relation (i.e., smaller, larger) between the training score and the generalization score agree with the theory?\n",
        "\n",
        "Print your motivation for the yes/no answer above, using at most 500 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [],
        "id": "bqjmotUw1mRm",
        "outputId": "1b8a0f45-e0c9-4651-c46c-41ca3d34a4a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score:  0.13067559014716523\n",
            "Generalization score:  -0.039856511099357506\n",
            "\n",
            "ANSWER\n",
            "Does the relation between the training score and the generalization score agree with the theory?  no\n",
            "Motivation:  No, the training score is larger than the generalization score. This is because the model is underfitting to the training data. This means that the model is not complex enough to capture the underlying patterns in the data. Underfitting is also a common problem in machine learning, and it can be avoided by using more complex models or by increasing the amount of training data.\n"
          ]
        }
      ],
      "source": [
        "# Print the training score (score on data used to train the model)\n",
        "training_score = model.score(Xtrain_scaled, Ytrain)\n",
        "print(\"Training score: \", training_score)\n",
        "\n",
        "# Print the generalization score (score on data used to estimate the generalization error)\n",
        "generalization_score = generalization_error\n",
        "print(\"Generalization score: \", generalization_score)\n",
        "\n",
        "print(\"\\nANSWER\")\n",
        "\n",
        "if training_score < generalization_score:\n",
        "    answer = \"yes\"\n",
        "    motivation = \"Yes, the training score is smaller than the generalization score. This is because the model is overfitting to the training data. This means that the model is memorizing the training data too well and is not able to generalize to new data. Overfitting is a common problem in machine learning, and it can be avoided by using regularization techniques.\"\n",
        "else:\n",
        "    answer = \"no\"\n",
        "    motivation = \"No, the training score is larger than the generalization score. This is because the model is underfitting to the training data. This means that the model is not complex enough to capture the underlying patterns in the data. Underfitting is also a common problem in machine learning, and it can be avoided by using more complex models or by increasing the amount of training data.\"\n",
        "\n",
        "print(\"Does the relation between the training score and the generalization score agree with the theory? \", answer)\n",
        "print(\"Motivation: \", motivation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-NIbEBJR1mRn"
      },
      "source": [
        "## TO DO: LEARN A STANDARD LINEAR MODEL\n",
        "Learn a standard linear model using scikit learn.\n",
        "\n",
        "Print the score of the model on the data used to learn it.\n",
        "\n",
        "Print the generalization \"score\" of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gjwvLIK51mRp",
        "outputId": "e0653b0a-1926-4bee-dc17-9768f9985ceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR MODEL\n",
            "Score of LR model on data used to learng it: 0.7111265101309925\n",
            "Generalization score of LR model: 0.6946788365499807\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "print(\"\\nLR MODEL\")\n",
        "lr = LinearRegression()\n",
        "lr.fit(Xtrain_scaled, Ytrain)\n",
        "num_folds = 10\n",
        "cv = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "cv_scores = []\n",
        "for train_index, test_index in cv.split(Xtrain_scaled, Ytrain):\n",
        "    X_train, X_test = Xtrain_scaled[train_index], Xtrain_scaled[test_index]\n",
        "    Y_train, Y_test = Ytrain[train_index], Ytrain[test_index]\n",
        "\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train, Y_train)\n",
        "    score = lr.score(X_test, Y_test)\n",
        "    cv_scores.append(score)\n",
        "\n",
        "generalization_error = np.mean(cv_scores)\n",
        "\n",
        "# Print the score of the model on the data used to learn it\n",
        "training_score = lr.score(Xtrain_scaled, Ytrain)\n",
        "print(\"Score of LR model on data used to learng it:\", training_score)\n",
        "\n",
        "# Print the generalization score (score on data used to estimate the generalization error)\n",
        "generalization_score = generalization_error\n",
        "print(\"Generalization score of LR model:\", generalization_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0yyRfwjCDtBL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}